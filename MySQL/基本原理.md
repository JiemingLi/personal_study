#  存储引擎架构

![MySQL体系架构](https://gitee.com/JieMingLi/document-pics/raw/master/20210606204741.png)

## 链接池

 ##   文件层

日志文件

- 错误日志
- 一般日志
- 二进制日志
- 慢查询日志

数据文件

- db.opt文件
- frm文件
- MYD文件
- MYI文件
- ibd文件
- ibdata1文件：undo日志
- Ib_logfile0, ib_logfile2文件：redo文件

配置文件

- 存放MySQL所有配置信息文件（my.cnf，m y.ini）



#  [运行机制](https://xiaolincoding.com/mysql/base/how_select.html)

![img](https://gitee.com/JieMingLi/document-pics/raw/master/20210606213605.jpg)



1，建立连接（<u>连接器</u>）；客户端和mysql建立半双工连接，每一个mysql的连接都会有一个线程来处理，通过线程的[状态标识](https://dev.mysql.com/doc/refman/5.7/en/general-thread-states.html)连接在做什么。

2，查询缓存（缓存器）；缓存select的查询结果和sql语句

不会使用到缓存的情况

- 查询语句使用sql_no_cache
- 查询结果大于mysql限制
- 查询参数中有不确定的参数

3，解析器：将客户端发送的SQL语法解析生成解析树。

4，查询优化器：根据解析书生成最优的执行计划，MySQL通过编译时优化和运行时优化生成优化策略。

5，存储引擎执行生成好的SQL语句，若开启缓存，则查询到的保存到缓存。如果数据量过多，通过增量的形式添加。



#  存储引擎

##  InnoDB

![img](https://gitee.com/JieMingLi/document-pics/raw/master/webp)

内存结构主要包括 Buffer Pool， Change Buffer， Log Buffer，Adaptive Hash Index四大组件构成。

###  [Buffer Pool](https://xiaolincoding.com/mysql/buffer_pool/buffer_pool.html)

缓冲池，以页为单位（4kB），默认大小为16KB。

底层采用链表的方式管理每个页， 每个页对Innodb访问的表记录和索引进行缓存，减少对磁盘的操作从而提高查询效率。

**Page管理机制**

- free page： 空闲page， 未被使用。
- clean page： 被使用page， 数据没有被修改过。
- dirty page： 脏页，被使用并且被修改的页，页的数据和数据库的数据不一致。

针对三种状态的page，InnoDB有三个链表管理。

- free list： 空闲缓冲区，管理free page
- flush list：表示要刷新到磁盘的缓冲区，管理dirty page，按照修改时间进行排序。
- lru list： 表示正在使用的缓冲区，管理clean page和dirty page， 缓冲区以midpoint为基点，基点前的列表为new列表区，存放访问较多的数据，基点后的列表成为old 列表区，存放访问较少的数据。

> 脏页放在flush list和lru list，但互不影响；flush list负责页的刷盘操作，lru负责页的释放。在lru list的page若触发释放，可能会导致flush list的page刷盘

**改进型LRU算法维护**

传统的LRU：

- 末尾淘汰法，新数据加入头部，释放空间从尾部淘汰。

改进后的LRU：

1. new list占 5/8，old list占3/8。 
2. 加入page的时候从middlepoint插入。
3. 若数据很快被访问<u>（针对new list和old list的page，如果是old list的page，则需要等待一段时间才会移到头部）</u>，则该page移动到new list的头部。
4. 若数据一直没有被访问，随着新page的不断插入，之前的插入的page不断往尾部移动，之前插入的page如果在new list，会到old list 再逐渐到old list的尾部，若在old list则逐渐到尾部，最后需要你数据交换或者内存不够的时候进行淘汰。

![Content is described in the surrounding text.](https://gitee.com/JieMingLi/document-pics/raw/master/innodb-buffer-pool-list.png)

>  每当从磁盘读取新的page到buffer pool的时候，会从free list判断是否有空闲页，若足够则对free list进行删除free page，并且添加到lru list；若不足够则对lru list进行page淘汰，分配给新读取的page。

**参数配置**

1， 可以把Buffer pool size 设置为内存的 60% - 80%。

2， 可以设置 [`innodb_buffer_pool_instances`](https://dev.mysql.com/doc/refman/5.6/en/innodb-parameters.html#sysvar_innodb_buffer_pool_instances) 大于1，避免遇到多线程读取buffer pool的瓶颈。在分为多个实例后，通过hash算法对每个page进行hash分配给多个buffer pool 实例中的1个。

> When the `InnoDB` buffer pool is large, many data requests can be satisfied by retrieving from memory. You might encounter bottlenecks from multiple threads trying to access the buffer pool at once. You can enable multiple buffer pools to minimize this contention. Each page that is stored in or read from the buffer pool is assigned to one of the buffer pools randomly, using a hashing function. Each buffer pool manages its own free lists, flush lists, LRUs, and all other data structures connected to a buffer pool, and is protected by its own buffer pool mutex.
>
> [Reference](https://dev.mysql.com/doc/refman/5.6/en/innodb-multiple-buffer-pools.html)

###  Change Buffer

> The change buffer is a special data structure that caches changes to [secondary index](https://dev.mysql.com/doc/refman/5.7/en/glossary.html#glos_secondary_index) pages when those pages are not in the [buffer pool](https://dev.mysql.com/doc/refman/5.7/en/glossary.html#glos_buffer_pool). The buffered changes, which may result from [`INSERT`](https://dev.mysql.com/doc/refman/5.7/en/insert.html), [`UPDATE`](https://dev.mysql.com/doc/refman/5.7/en/update.html), or [`DELETE`](https://dev.mysql.com/doc/refman/5.7/en/delete.html) operations (DML), are merged later when the pages are loaded into the buffer pool by other read operations.
>
> Unlike [clustered indexes](https://dev.mysql.com/doc/refman/5.7/en/glossary.html#glos_clustered_index), secondary indexes are usually nonunique, and inserts into secondary indexes happen in a relatively random order. Similarly, deletes and updates may affect secondary index pages that are not adjacently located in an index tree. Merging cached changes at a later time, when affected pages are read into the buffer pool by other operations, avoids substantial random access I/O that would be required to read secondary index pages into the buffer pool from disk.
>
> https://dev.mysql.com/doc/refman/5.7/en/innodb-change-buffer.html



写缓冲区，默认占用Buffer pool的25%空间

对于普通索引来说在进行DML的操作时候，**如果BP没有对应的数据，不会立刻把数据从磁盘加载到Buffer Pool，而是在Change Buffer中缓冲变更**，等后续数据读取的时候再把变更和数据合并到Buffer Pool，把变更加入change buffer可以减少了磁盘的随机访问，加快响应速度，读取的时候也会合并数据（触发merge的时机看下文）保证数据的一致性。

change buffer可以看成也是一个数据页，需要被持久化到 系统表空间（ibdata1），以及把这个change buffer页的改动记录在redo log里，事后刷进系统表空间（ibdata1）。

> 仅适用于非唯一性索引：如果是唯一索引，innodb在更新数据库的时候会查询一次数据库，进行唯一性确认。

**原理**

当需要更新一个数据页时

- 如果数据页在内存中就直接更新

- 如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要**访问**这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作，记录redo log和binlog。

merge： change buffer的merge操作，先把change buffer的操作更新到内存的数据页中，此操作写到redo log中(只要内存中数据有更新，都会记录redo log和binlog)，这样保证了崩溃恢复。

**触发merge的时机**

- 访问数据页会触发 merge
- 系统有后台线程会定期 merge
- 数据库正常关闭（shutdown）

**使用的场景**

- 针对普通索引，不针对唯一索引。

- 为什么不面向唯一索引？因为所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入 (4,400) 这个记录，就要先判断现在表中是否已经存在 k=4 的记录，而这必须要将数据页读入内存才能判断。校验的时候需要把相关的页读取到内存，既然都读取到内存，没必要记录change buffer，直接进行页操作，把读出来的页变成脏页再进行刷新。
- 对于普通索引来说，对于写多读少的情况，收益会更大。假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，**反而增加了 change buffer 的维护代价**。

[插入缓冲区的特性](https://cloud.tencent.com/developer/article/1533766)

[change buffer](https://time.geekbang.org/column/article/70848)

###  Log Buffer 

缓存redo和undo的日志

通过innod_flush_log_at_trx_commit控制日志刷盘操作

- 0：每隔1s进行写文件到操作写文件和刷盘（写文件：log buffer ->os cache，刷盘：os cache -> 磁盘文件），最多丢失1s的数据。
- 1：事物提交就立刻写文件和刷盘，数据不会丢失，但是性能比较差。
- 2：事务提交，立刻写日志文件，每隔1s进行刷盘。



###  线程模型

![image.png](https://gitee.com/JieMingLi/document-pics/raw/master/bVcQJxC.png)

**IO thread**

使用大量的AIO进行读写才做，提高数据库的性能。

主要有read，write，insert buffer log 四种线程。

- read thread：将数据从磁盘读取到缓存的page页
- write thead： 将缓存脏页刷新到磁盘
- log thread： 将日志缓冲区内容刷新到磁盘
- inert buffer thread ： 将写缓冲(change buffer)的内容刷新到磁盘

**Purge thread**

事务提交后，使用的undo日志不再使用，需要Purge thread回收分配好的页（缓冲区和磁盘的页）

**Page cleaner thread**

将脏数据刷新到磁盘（通过调用write thread处理），脏页的数据刷盘之后可以继续使用。

**Master thread**

是InnoDB的主线程，负责**调度其他的各个线程**，优先级最高，将缓冲池的数据异步刷新到磁盘。

内部有2个主处理，分别是每隔1s和每隔10s的处理。

每秒的操作

- 刷新日志缓冲区数据到磁盘（无条件），即使事务没有提交，InnoDB仍然每秒会将重做日志缓冲中的内容刷新到重做日志文件，这可以很好的解释大事务提交时间短的原因。
- 合并写缓冲区数据，根据IO的读写压力决定
- 刷新脏页数据到磁盘，根据脏页比例到达75%才操作

每10s的操作

- 刷新脏页到磁盘（有可能）
- 合并写缓冲区数据（无条件）
- 刷新日志缓冲区（无条件），和隔1s的一样 。
- 删除无用的undo页（无条件）



### 数据文件

数据存储结构示意图

![ibd_arch](https://gitee.com/JieMingLi/document-pics/raw/master/1861029-20210604101356850-1096573215.jpg)



**Tablespce（表空间）**

表空间存储多个ibd数据文件，ibd文件存储着表的记录和索引，一个idb文件包含多个segment。

**Segment（段）**

用于管理多个extent，在ibd文件里有数据段，索引段（非叶子结点），回滚段。

**Extent（区）**

一个区固定包含64个页，大小为1M。表空间不足的，需要分配新的页资源的时候，不会单个页分配，而是按照区进行区分。

**Page**

存储多个Row记录，页大小为16K。

类型：数据页，undo页，系统页，事务数据页，大的BLOB对象页。（需要参考文档）

**Row**

行，包含记录的字段值，事务 ID， 滚动指针，字段指针，字段属性等。



page是文件的基本单位，任何的page都有page header，page trailer， page body组成



### 格式

**文件格式(file-format)**

在早期的InnoDB版本中，文件格式只有一种，随着InnoDB引擎的发展，出现了新文件格式，用于支持新的功
能。 目前innoDB只支持两种文件格式：Antelope 和 Barracuda。

- Antelope: 先前未命名的，最原始的InnoDB文件格式，它支持两种行格式：FOMPACT和 REDUNDANT
  MysQL 5.6及其以前版本默认格式为antelope。
- Barracuda:  新的文件格式。它支持InnoDB的所有行格式，包括新的行格式：COMPRESSED 和
  DYMANIC。

> 通过innodb_file_format 配置参数可以设置InnoDB文件格式，之前默认值为Antelope，5.7版本开始改为
> **Barracuda**.

**行格式(row-format)**

表的行格式决定行是如何物理存储，会影响DML的性能。在单个页中如果可以存储多个行记录，查询和索引会更有效率，并且Buffer Pool中所占用的内存越少，写入时所需要的IO就越少。

![四种行格式对比](https://img-blog.csdnimg.cn/20191229231858154.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NodWlmYTIwMDg=,size_16,color_FFFFFF,t_70)

DYNAMIC和COMPREESSED新格式引入新功能：数据压缩和增强型长列数据的页外存储和大索引前缀。

如果某些字段信息过长，无法存储在B树节点中，这时候会被单独分配空间，此时被称为溢出页，该字段被称
为页外列。

**redundant格式**

表会将变长列值前786个字节存储在B树的索引记录，溢出的存储在溢出页中；对于大于等于786个字节的固定长度字段会转化为变长字段，从而溢出的继续在溢出页存储。

**compact格式**

和redundant格式相比较，compact的行格式减少20%的行存储空间，代价会消耗CPU的资源。若系统是磁盘敏感型的话，使用compact会更快，若是CPU敏感型，则会更慢。

**DYMANIC格式**

使用DYNAMIC行格式，InnoDB会将表中长可变长度的列值完全存储在页外，而索引记录只包含指向溢出
页的20字节指针。 大于或等于768字节的固定长度字段编码为可变长度字段。 DYNAMIC行格式支持大索
引前缀，最多可以为3072字节，可通过innodb_large_prefix参数控制。

**COMPRESSED 行格式**
COMPRESSED行格式提供与DYNAMIC行格式相同的存储特性和功能，但增加了对表和索引数据压缩的支
持。

**如何修改文件格式**

在创建表和索引的时候，文件格式应用于每个InnoDB表数据文件。修改文件格式的方法就是重新创建表和索引。

一般情况下，如果row_format为REDUNDANT、COMPACT，文件格式为Antelope；如果row._format为
DYNAMIC和COMPRESSED，文件格式为Barracuda。所以 修改文件格式的最简单的方法就是修改表的row_format

```sql
ALTER TABLE 表名 ROW_FORMAT = 行格式类型
```



### [undo log](https://xiaolincoding.com/mysql/log/how_update.html)

事务开始之前，会把将要修改的数据记录在undo log，当事务回滚或者数据库崩溃的时候利用undo log进行数据恢复

Undo log的产生与销毁 ：事务开始前产生；事务在提交时，不会立刻删除undo log，innodb会把 该事务对应的undo log放出删除列表，后续会通过后台线程purge thread进行回收处理。Undo log属于逻辑日志，<u>记录一个变化的过程</u>。

Undo Log存储：undo log采用段的方式管理和记录。在innodb数据文件中包含一种roilback segment回滚
段，内部包含1024个undo log segment。可以通过下面一组参数来控制Undo log存储。

**作用** 

1，实现事务的原子性

Undo Log 是为了实现事务的原子性而出现的产物。事务处理过程中，如果出现了错误或者用户执行了
ROLLBACK 语句，MySQL 可以利用 Undo Log 中的备份将数据恢复到事务开始之前的状态。

2， 实现MVCC机制

Undo Log 在MysQL InnoDB 存储引擎中用来实现多版本并发控制。事务未提交之前，Undo Log 保存了
未提交之前的版本数据，Undo Log 中的数据可作为数据旧版本快照供其他并发事务进行快照读。

![MVCC](https://gitee.com/JieMingLi/document-pics/raw/master/005SjMHzly1gq42bai7jtj31bu0hmtcg.jpg)

### [redo log & binlog](https://xiaolincoding.com/mysql/log/how_update.html)

Redo Log：指事务中修改的任何数据，将最新的数据备份存储的位置（Redo Log），被称为重做日志。
Redo Log 的生成和释放：随着事务操作的执行，就会生成Redo Log，在内存的数据发生改变时会将产生 Redo Log写入Log Buffer，真正把日志写到 redo log 文件（文件名是 ib_logfile+ 数字），是在执行 **commit** 语句的时候做的。等事务操作的脏页写入到磁盘之后，Redo Log的使命也就完成了，Redo Log占用的空间就可以重用（被覆盖写入）。

**工作原理**

Redo Log 是为了实现事务的持久性而出现的产物。防止在发生故障的时间点，尚有脏页未写入表的 IBD 文件中，在重启 MySQL 服务的时候，根据 Redo Log 进行重做写入到IBD文件中，从而达到事务的未入磁盘数据进行持久化这一特性。

![redo log工作原理](https://gitee.com/JieMingLi/document-pics/raw/master/005SjMHzly1gq42goe7c1j319q0wo430.jpg)

**磁盘IO**

1. 事务每次提交的时候，会把数据放在buffer pool中，不会立刻写入磁盘，避免磁盘IO过高影响性能。

2. 在更新数据较为离散的情况下，比如更新id=1和id=1001的用户，可能会产生随机的io，效率低。
   写入redo log属于顺序写入io，顺序写入磁盘的io效率比随机写入的磁盘io高，因为顺序写入可能只需要写入1个页就完成。

**redo log写入机制**

write pos： 当前记录的位置，一边写一边后移，写到最后一个文件末尾后就回到 0 号文件开头

checkpoint：当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件；

Redo Log 文件内容是以**顺序循环**的方式写入文件，写满时则回湖到第一个文件，进行覆盖写。

![写入机制](https://gitee.com/JieMingLi/document-pics/raw/master/005SjMHzly1gq43vnhxomj31900g2ta1.jpg)write pos 和 checkpoint 之间还空着的部分，可以用来记录新的操作。如果 write pos 追上checkpoint，表示写满，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint推进一下。



**配置参数**

每个InnoDB存储引擎至少有1个重做日志文件组（group），每个文件组至少有2个重做日志文件，默认为ib_logfile0和ib_logfile1。

Redo Buffer 持久化到 Redo Log 的策略，可通过 Innodb_flush_log_at_trx_commit 设置：

- 0：每秒提交 Redo buffer ->OS cache -> flush cache to disk，可能丢失一秒内的事务数据。由后台Master线程每隔 1秒执行一次操作。
- 1（默认值）：每次事务提交执行 Redo Buffer -> OS cache -> flush cache to disk，最安全，性能最差的方式。
- 2：每次事务提交执行 Redo Buffer -> OS cache，然后由后台Master线程再每隔1秒执行OScache -> flush cache to disk 的操作。

> 一般建议选择取值2，因为 MySQL 挂了数据没有损失，整个服务器挂了才会损失1秒的事务提交数据。

![redo log 参数](https://gitee.com/JieMingLi/document-pics/raw/master/005SjMHzly1gq443c8n6cj319y0ho0wt.jpg)

Binlog文件记录模式有STATEMENT、ROW和MIXED三种，具体含义如下：

- ROW（row-based replication, RBR）：日志中会记录每一行数据被修改的情况，然后在slave端对相同的数据进行修改。

  优点：能清楚记录每一个行数据的修改细节，能完全实现主从数据同步和数据的恢复。

  缺点：批量操作，会产生大量的日志，尤其是alter table会让日志暴涨。

- STATMENT（statement-based replication, SBR）：每一条被修改数据的SQL都会记录到master的Binlog中，slave在复制的时候SQL进程会解析成和原来master端执行过的相同的SQL再次执行。简称SQL语句复制。

  优点：日志量小，减少磁盘IO，提升存储和恢复速度

  缺点：在某些情况下会导致主从数据不一致，比如last_insert_id()、now()等函数。

- MIXED（mixed-based replication, MBR）：以上两种模式的混合使用，一般会使用STATEMENT模式保存binlog，对于STATEMENT模式无法复制的操作使用ROW模式保存binlog，MySQL会根据执行的SQL语句选择写入模式。

**写入机制**

- 根据记录模式和操作触发event事件生成log event（事件触发执行机制）
- 将事务执行过程中产生log event写入缓冲区，每个事务线程都有一个缓冲区Log Event保存在一个binlog_cache_mngr数据结构中，在该结构中有两个缓冲区，一个是stmt_cache，用于存放不支持事务的信息；另一个是trx_cache，用于存放支持事务的信息。
- 事务在提交阶段会将产生的log event写入到外部binlog文件中。不同事务以串行方式将log event写入binlog文件中，所以一个事务包含的log event信息在binlog文件中是连续的，中间不会插入其他事务的log event。binlog是引/擎插件上层的功能，事务提交第一个就会调用binlog功能接口，然后再调用其他存储引孳的功能接口。因此先写binlog，然后再执行innodb的redolog/undo和脏页刷新操作

​	

**Redo Log和Binlog的区别**

- Redo Log是属于InnoDB引擎功能，Binlog是属于MySQL Server自带功能，并且是以二进制文件记录。
- Redo Log属于物理日志，记录该数据页更新状态内容，Binlog是逻辑日志，记录更新过程。
- Redo Log日志是循环写，日志空间大小是固定，Binlog是追加写入，写完一个写下一个，不会覆盖使用。
- Redo log作为服务器异常，宕机后事务数据自动恢复使用，Binlog可以作为主从复制和数据恢复(被动)使用

#### 疑问

- sync_binlog和组提交定位是否冲突？ https://my.oschina.net/u/3847203/blog/4565245 
- binlog的mixed模式，什么时候会用statement，什么时候会用row？

### 补充

```tex
也就是 binlog 写完，redo log 还没 commit 前发生 crash，那崩溃恢复的时候 MySQL 会怎么处理？我们先来看一下崩溃恢复时的判断规则。 如果 redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交； 如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完整：a. 如果是，则提交事务；b. 否则，回滚事务。


1、redolog在prepare阶段持久化到磁盘（可能失败） 2、紧接着binlog持久化（可能失败） 3、最后redolog commit（可能失败） 情况一：在1处mysql异常重启，redo log没有fsync，内存丢失，直接回滚，不影响数据一致性； 情况二：redolog fsync成功，但是binlog写入错误，此时mysql异常重启，现在有redolog的磁盘数据没有binlog的数据，此时检测redolog处于prepare阶段，但是没有binlog，回滚（虽然刚刚redolog fsync了但是不影响数据一致性，因为redolog的操作并没有写入mysql，也永远不会写入mysql）； 情况三：binlog完整但未commit，此时检测redolog处于prepare阶段，且binlog完整但未提交，默认添加commit标记，进而提交，写入mysql，满足数据一致性； 情况四：binlog完整且提交，写入musql，满足一致性；


如果把 innodb_flush_log_at_trx_commit 设置成 1，那么 redo log 在 prepare 阶段就要持久化一次，因为有一个崩溃恢复逻辑是要依赖于 prepare 的 redo log，再加上 binlog 来恢复的。


通常我们说 MySQL 的“双 1”配置，指的就是 sync_binlog 和 innodb_flush_log_at_trx_commit 都设置成 1。也就是说，一个事务完整提交前，需要等待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog。

和sync_binlog的区别： sync_binlog=N，事务write后响应给客户端，N和事务之间宕机，数据会丢失； binlog_group_commit_sync_delay = N，积累事务到N个，fsync后响应客户端


主从同步，通过binlog
1， 一主多从
2， 从机的数量并不是越多越好，对于主库来说，从库越多，load dump线程数也得上去，还得需要考虑主库的带宽，cpu资源等
3， 同步复制，异步复制，半同步复制（过半机制，在raft，gossipy协议中也都有应用）

```



### 复习资料

[undo log, redo log, binlog的作用](https://xiaolincoding.com/mysql/log/how_update.html)
